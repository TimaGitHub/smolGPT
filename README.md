# smolGPT ğŸ¾

*smol but mighty.*


You've seen [openai/gpt-2](https://github.com/openai/gpt-2).

You've seen [karpathy/minGPT](https://github.com/karpathy/mingpt).

You've even seen [karpathy/nanoGPT](https://github.com/karpathy/nanogpt)!

You might have even seen [jaymody/picoGPT](https://github.com/jaymody/picoGPT)!

But you have never seen smolGPT!!!

### What is **smolGPT**?

**smolGPT** is a small-scale version of the GPT architecture, built for research and learning purposes. This is a **research project** focused on understanding and experimenting with the inner workings of GPT-like architectures.

What makes **smolGPT** special? Itâ€™s built using **[pycandle-2](https://github.com/TimaGitHub/pycandle-2)**, a lightweight machine learning library that Iâ€™ve created from scratch. By using **NumPy** as the foundation, the goal was to implement a minimalist GPT model without relying on large, heavyweight frameworks like TensorFlow or PyTorch.
 This library allows you to run, train, and experiment with machine learning models while keeping things easy to understand.

---


picoGPT features:
* Fast? âŒ smolPGT is supaSLOW ğŸŒ We say ğŸš« to CV-cache, Quantization and Distillation 
* Training code? âœ… Yes, but it may cause you ğŸ’¢!
* top-p sampling? âŒ top-k? âœ… temperature? âŒ categorical sampling?! âŒ greedy? âœ…
* Self-made??? âœ…âœ… YESS!!! I made it completely from scratch in numpyğŸ˜²ğŸ˜²ğŸ˜² 
* Scalable? **(à©­Ëƒá´—Ë‚)à©­** You may build whatever architecture you want with **PyCandle**. 

**GPT2-3-4?**, **Llama 1-2-3?** ğŸ˜ğŸ‘ŒğŸ”¥ just provide model weightsğŸ¤”



### ğŸ“¦ Installation

To install **smolGPT** with **pycandle-2**, follow these simple steps:

1. Clone the repository:
   ```bash
   git clone https://github.com/TimaGitHub/smolGPT.git
   cd smolGPT
   ```

2. Install the required dependencies:
   ```bash
   pip install -r requirements.txt
   ```

3. Run the model:
   ```bash
   python main.py
   ```

And thatâ€™s it! Youâ€™re ready to start generating text with **smolGPT**. ğŸ˜…

---

### ğŸš€ Example Usage

With **smolGPT**, you can quickly generate text. Hereâ€™s an example:

```bash
python main.py --prompt "Hello! i am a language model," --max_new_tokens 30 --model 124M --device gpu --topk 30
```
#### **output ğŸ˜…**

```bach
Hello! i am a language model, I have no language background and this is not a problem

Anonymous 01/11/15 (Thu) 04:09:19 AM No.
```

The modelâ€™s lighthearted and playful nature makes it a fun tool for experimenting with GPT-like architectures (**124M**, **345M**, **762M**, **1542M**) ğŸ˜†

---

### ğŸ’¡ Why **smolGPT**?

- **Learning-Focused**: Built to explore and experiment with GPT architecture, not necessarily to run on embedded or resource-limited systems.
- **Small Size**: Perfect for local experiments and educational purposes.
- **Built with **pycandle-2****: Leverages a custom **NumPy**-based machine learning library for simplicity and efficiency.
- **Lightweight**: While small, it retains the core principles of GPT models.

---

### ğŸ¤– Contributing

If youâ€™d like to improve **smolGPT** or contribute to **pycandle-2**, feel free to fork the repository, make your changes, and submit a pull request. New ideas and contributions are always welcome!
